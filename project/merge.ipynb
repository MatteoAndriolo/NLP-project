{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27123e72730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import sort as tsort, Tensor\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.manual_seed(99)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arc-Eager Parser and Oracle\n",
    "Arc Eager Parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "NOMOVE = -1\n",
    "LEFT_ARC = 0\n",
    "RIGHT_ARC = 1\n",
    "REDUCE = 2\n",
    "SHIFT = 3\n",
    "\n",
    "IS_FINAL = -10\n",
    "EMPTY = -1\n",
    "\n",
    "\n",
    "class ArcEager:\n",
    "    def __init__(self, sentence):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            sentence: list of words | first word must be <ROOT>\n",
    "            debug: if True print each move\n",
    "        \"\"\"\n",
    "        if all([isinstance(x, str) for x in sentence]):\n",
    "            if sentence[0] != \"<ROOT>\":\n",
    "                raise Exception(\"ERROR: first word must be <ROOT>\")\n",
    "        elif all([isinstance(x, int) for x in sentence]):\n",
    "            if sentence[0] != 1:  # token of ROOT is 1\n",
    "                raise Exception(\"ERROR: first word must be -1\")\n",
    "        else:\n",
    "            raise Exception(\"ERROR: sentence must be list of words or list of ints\")\n",
    "\n",
    "        self.sentence = sentence\n",
    "        self.buffer = [i for i in range(len(self.sentence))]\n",
    "        self.stack = []\n",
    "\n",
    "        self.list_arcs = [-1 for _ in range(len(self.sentence))]\n",
    "        self.list_moves = []\n",
    "        self.list_configurations = []\n",
    "\n",
    "        # Do first shift -> add ROOT to stack\n",
    "        self.stack.append(self.buffer.pop(0))\n",
    "        self.is_finished = False\n",
    "\n",
    "    def update_configurations(self, move):\n",
    "        \"\"\"to do before each move\"\"\"\n",
    "        if move == NOMOVE:\n",
    "            self.list_configurations.append([EMPTY, EMPTY])\n",
    "            self.list_moves.append(NOMOVE)\n",
    "        if len(self.stack) > 0:\n",
    "            self.list_configurations.append(\n",
    "                [self.stack[-1], self.buffer[0] if len(self.buffer) > 0 else EMPTY]\n",
    "            )\n",
    "            self.list_moves.append(move)\n",
    "\n",
    "    def left_arc(self):\n",
    "        self.update_configurations(LEFT_ARC)\n",
    "        s1 = self.stack.pop(-1)\n",
    "        b1 = self.buffer[0]\n",
    "        self.list_arcs[s1] = b1\n",
    "\n",
    "    def right_arc(self):\n",
    "        if not is_right_possible(self):\n",
    "            self.nomove()\n",
    "            return\n",
    "        self.update_configurations(RIGHT_ARC)\n",
    "        s1 = self.stack[-1]\n",
    "        b1 = self.buffer.pop(0)\n",
    "        self.stack.append(b1)\n",
    "        self.list_arcs[b1] = s1\n",
    "\n",
    "    def shift(self):\n",
    "        self.update_configurations(SHIFT)\n",
    "        self.stack.append(self.buffer.pop(0))\n",
    "\n",
    "    def reduce(self):\n",
    "        self.update_configurations(REDUCE)\n",
    "        self.stack.pop()\n",
    "\n",
    "    def nomove(self):\n",
    "        self.is_finished = True\n",
    "        self.update_configurations(NOMOVE)\n",
    "\n",
    "    def do_move(self, move: int):\n",
    "        if move == LEFT_ARC:\n",
    "            self.left_arc()\n",
    "        elif move == RIGHT_ARC:\n",
    "            self.right_arc()\n",
    "        elif move == SHIFT:\n",
    "            self.shift()\n",
    "        elif move == REDUCE:\n",
    "            self.reduce()\n",
    "        elif move == NOMOVE:\n",
    "            self.nomove()\n",
    "        return move\n",
    "\n",
    "    def is_tree_final(self):\n",
    "        return self.is_finished or (len(self.stack) == 1 and len(self.buffer) == 0)\n",
    "\n",
    "    def print_configuration(self):\n",
    "        s = [self.sentence[i] for i in self.stack]\n",
    "        b = [self.sentence[i] for i in self.buffer]\n",
    "        print(s, b)\n",
    "        print(self.stack, self.buffer)\n",
    "        print(self.list_arcs)\n",
    "\n",
    "    def get_list_moves(self):\n",
    "        return self.list_moves\n",
    "\n",
    "    def get_list_configurations(self):\n",
    "        return self.list_configurations\n",
    "\n",
    "    def get_list_arcs(self):\n",
    "        return self.list_arcs\n",
    "\n",
    "    def get_configuration_now(self):\n",
    "        if self.is_tree_final():\n",
    "            conf = [-1, -1]\n",
    "        else:\n",
    "            conf = [self.stack[-1]]\n",
    "            if len(self.buffer) == 0:\n",
    "                conf.append(-1)\n",
    "            else:\n",
    "                conf.append(self.buffer[0])\n",
    "        return conf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oracle:\n",
    "    def __init__(self, parser, gold_tree: List[int]):\n",
    "        self.parser = parser\n",
    "        self.gold = list(map(int, gold_tree))\n",
    "\n",
    "        # Check correctness of input\n",
    "        if self.gold[0] != -1:\n",
    "            print(\"ERROR: gold tree must start with -1\")\n",
    "            exit(-1)\n",
    "\n",
    "    \"\"\"\n",
    "    i: top of stack, j: top of buffer\n",
    "    if there's a link j -> i then return LEFT-ARC\n",
    "    else if there's a link i -> j then return RIGHT-ARC\n",
    "    else if there's a link k <-/-> j, k < i then return REDUCE\n",
    "    else return SHIFT \n",
    "    \"\"\"\n",
    "\n",
    "    def is_left_arc_gold(self):\n",
    "        # first element of the of the buffer is the gold head of the topmost element of the stack\n",
    "        # if empty lists or if top has no head -> return False\n",
    "        if len(self.parser.buffer) == 0 or self.parser.stack[-1] == 0:  # if top is ROOT\n",
    "            return False\n",
    "\n",
    "        s = self.parser.stack[-1]\n",
    "        b = self.parser.buffer[0]  # [0]\n",
    "        if self.gold[s] != b:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def is_right_arc_gold(self):\n",
    "        # if topmost stack element is gold head of the first element of the buffer\n",
    "        if len(self.parser.buffer) == 0:\n",
    "            return False\n",
    "\n",
    "        s = self.parser.stack[-1]\n",
    "        b = self.parser.buffer[0]  # [0]\n",
    "        if self.gold[b] != s:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def is_reduce_gold(self):\n",
    "        s = self.parser.stack[-1]\n",
    "        if (\n",
    "            self.parser.list_arcs[s] == -1 or s == 0\n",
    "        ):  # if top has no head or if top is ROOT\n",
    "            return False\n",
    "        if len(self.parser.buffer) == 0:  # if buffer is empty\n",
    "            if (\n",
    "                self.parser.list_arcs[s] != -1 and s != 0\n",
    "            ):  # if top has a head and top is not ROOT\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "        for i in range(0, len(self.parser.buffer)):\n",
    "            b = self.parser.buffer[i]\n",
    "            if (\n",
    "                self.gold[b] == s or self.gold[s] == b\n",
    "            ):  # if there's a link k <-/-> j, k < i then do not reduce\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def is_shift_gold(self):\n",
    "        if len(self.parser.buffer) == 0:\n",
    "            return False\n",
    "        if self.is_left_arc_gold() or self.is_right_arc_gold() or self.is_reduce_gold():\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def get_next_move(self, do_it=False):\n",
    "        if self.parser.is_tree_final():\n",
    "            return IS_FINAL\n",
    "        if self.is_left_arc_gold():\n",
    "            return LEFT_ARC\n",
    "        elif self.is_right_arc_gold():\n",
    "            return RIGHT_ARC\n",
    "        elif self.is_reduce_gold():\n",
    "            return REDUCE\n",
    "        elif self.is_shift_gold():\n",
    "            return SHIFT\n",
    "        else:\n",
    "            print(\"NO MOVE\")\n",
    "            print(self.gold)\n",
    "            print(self.parser.list_arcs)\n",
    "            self.parser.print_configuration()\n",
    "            exit(-5)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_left_possible(parser):\n",
    "    return len(parser.stack) >= 1 and len(parser.buffer) >= 1 and parser.stack[-1] != 0\n",
    "\n",
    "\n",
    "def is_right_possible(parser):\n",
    "    return len(parser.stack) >= 1 and len(parser.buffer) >= 1\n",
    "\n",
    "\n",
    "def is_shift_possible(parser):\n",
    "    return len(parser.buffer) >= 1\n",
    "\n",
    "\n",
    "def is_reduce_possible(parser):\n",
    "    return len(parser.stack) >= 1 and parser.list_arcs[parser.stack[-1]] != -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser used for output of the model in order to accept or reject moves (feasible or unfeasible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_moves(parsers: List[ArcEager], moves: Tensor):\n",
    "    _, indices = tsort(moves, descending=True)\n",
    "    list_moves = []\n",
    "    for i in range(len(parsers)):\n",
    "        noMove = True\n",
    "        if parsers[i].is_tree_final():\n",
    "            list_moves.append(NOMOVE)\n",
    "            continue\n",
    "        else:\n",
    "            for j in range(4):\n",
    "                if indices[i][j] == LEFT_ARC and is_left_possible(parsers[i]):\n",
    "                    list_moves.append(LEFT_ARC)\n",
    "                    noMove = False\n",
    "                    break\n",
    "                elif indices[i][j] == RIGHT_ARC and is_right_possible(parsers[i]):\n",
    "                    list_moves.append(RIGHT_ARC)\n",
    "                    noMove = False\n",
    "                    break\n",
    "                elif indices[i][j] == REDUCE and is_reduce_possible(parsers[i]):\n",
    "                    list_moves.append(REDUCE)\n",
    "                    noMove = False\n",
    "                    break\n",
    "                elif indices[i][j] == SHIFT and is_shift_possible(parsers[i]):\n",
    "                    list_moves.append(SHIFT)\n",
    "                    noMove = False\n",
    "                    break\n",
    "        if noMove:\n",
    "            list_moves.append(NOMOVE)\n",
    "    return list_moves\n",
    "\n",
    "\n",
    "def generate_gold(sentence: List[str], gold: List[int]):\n",
    "    \"\"\"\n",
    "    Generate moves configurations heads for a given parser and oracle\n",
    "\n",
    "    input:\n",
    "        parser: ArcEager object\n",
    "        oracle: Oracle object\n",
    "    returns:\n",
    "        moves: list of moves\n",
    "        configurations: list of configurations\n",
    "        arcs: list of heads\n",
    "\n",
    "    \"\"\"\n",
    "    parser: ArcEager = ArcEager(sentence)\n",
    "    oracle: Oracle = Oracle(parser, gold)\n",
    "\n",
    "    while not parser.is_tree_final():\n",
    "        if parser.do_move(oracle.get_next_move()) == NOMOVE:\n",
    "            print(\"ERROR: NOMOVE\")\n",
    "\n",
    "    return parser.list_moves, parser.list_configurations, parser.list_arcs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_projective(head):\n",
    "    for i in range(len(head)):\n",
    "        if head[i] == -1:\n",
    "            continue\n",
    "        left = min(i, head[i])\n",
    "        right = max(i, head[i])\n",
    "\n",
    "        for j in range(0, left):\n",
    "            if head[j] > left and head[j] < right:\n",
    "                return False\n",
    "        for j in range(left + 1, right):\n",
    "            if head[j] < left or head[j] > right:\n",
    "                return False\n",
    "        for j in range(right + 1, len(head)):\n",
    "            if head[j] > left and head[j] < right:\n",
    "                return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define batchsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (C:/Users/andri/.cache/huggingface/datasets/universal_dependencies/en_lines/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n",
      "Found cached dataset universal_dependencies (C:/Users/andri/.cache/huggingface/datasets/universal_dependencies/en_lines/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n",
      "Found cached dataset universal_dependencies (C:/Users/andri/.cache/huggingface/datasets/universal_dependencies/en_lines/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n",
      "Loading cached processed dataset at C:\\Users\\andri\\.cache\\huggingface\\datasets\\universal_dependencies\\en_lines\\2.7.0\\1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7\\cache-cc2d09ceab675841.arrow\n",
      "Loading cached processed dataset at C:\\Users\\andri\\.cache\\huggingface\\datasets\\universal_dependencies\\en_lines\\2.7.0\\1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7\\cache-e425a16c80481592.arrow\n",
      "Loading cached processed dataset at C:\\Users\\andri\\.cache\\huggingface\\datasets\\universal_dependencies\\en_lines\\2.7.0\\1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7\\cache-1bbffe7f1d0ebbcc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 3176, validation_dataset: 1032, test_dataset: 1035\n",
      "PROJECTIVE -> train_dataset: 2922, validation_dataset: 930, test_dataset: 968\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"universal_dependencies\", \"en_lines\", split=\"train\")\n",
    "test_dataset = load_dataset(\"universal_dependencies\", \"en_lines\", split=\"test\")\n",
    "validation_dataset = load_dataset(\n",
    "    \"universal_dependencies\", \"en_lines\", split=\"validation\"\n",
    ")\n",
    "print(\n",
    "    f\"train_dataset: {len(train_dataset)}, validation_dataset: {len(validation_dataset)}, test_dataset: {len(test_dataset)}\"  # type:ignore\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.filter(\n",
    "    lambda x: is_projective([-1] + list(map(int, x[\"head\"])))\n",
    ")\n",
    "validation_dataset = validation_dataset.filter(\n",
    "    lambda x: is_projective([-1] + list(map(int, x[\"head\"])))\n",
    ")\n",
    "test_dataset = test_dataset.filter(\n",
    "    lambda x: is_projective([-1] + list(map(int, x[\"head\"])))\n",
    ")\n",
    "print(\n",
    "    f\"PROJECTIVE -> train_dataset: {len(train_dataset)}, validation_dataset: {len(validation_dataset)}, test_dataset: {len(test_dataset)}\"  # type:ignore\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BiLSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNData:\n",
    "    def __init__(self, tokens, confs, moves, heads) -> None:\n",
    "        self.enc_tokens = tokens\n",
    "        self.confs = confs\n",
    "        self.moves = moves\n",
    "        self.heads = heads\n",
    "        # self.dictionary = dictionary\n",
    "\n",
    "\n",
    "def extract_att(data: List[NNData], attribute: str):\n",
    "    return [getattr(d, attribute) for d in data]\n",
    "\n",
    "\n",
    "def create_dictionary(dataset, threshold: int = 3) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Extract from corpus vocabulary V of unique words that appear at least threshold times.\n",
    "    input:\n",
    "        dataset: list of sentences, each sentence is a list of words\n",
    "        treashold: minimum number of times a word must appear in the corpus to be included in the vocabulary\n",
    "\n",
    "    output:\n",
    "        map: dictionary of word/index pairs. This is our embedding list\n",
    "    \"\"\"\n",
    "    dic = {}  # dictionary of word counts\n",
    "    for sample in dataset:\n",
    "        for word in sample[\"tokens\"]:\n",
    "            if word in dic:\n",
    "                dic[word] += 1\n",
    "            else:\n",
    "                dic[word] = 1\n",
    "\n",
    "    map = {}  # dictionary of word/index pairs. This is our embedding list\n",
    "    map[\"<pad>\"] = 0\n",
    "    map[\"<ROOT>\"] = 1\n",
    "    map[\"<unk>\"] = 2  # used for words that do not appear in our list\n",
    "\n",
    "    next_indx = 3\n",
    "    for word in dic.keys():\n",
    "        if dic[word] >= threshold:\n",
    "            map[word] = next_indx\n",
    "            next_indx += 1\n",
    "\n",
    "    return map\n",
    "\n",
    "\n",
    "def process_sample(sample, emb_dictionary, get_gold_path=False):\n",
    "    \"\"\"\n",
    "    Process a sample from the dataset\n",
    "    1. Add [\"<ROOT>\"] to the beginning of the sentence and [-1] to the beginning of the head\n",
    "    2. Encode the sentence and the gold path\n",
    "\n",
    "\n",
    "    :param         tokens: tokens of a sentence\n",
    "    :param emb_dictionary: dictionary of word/index pairs\n",
    "    :param  get_gold_path: if True, we also return the gold path and gold moves\n",
    "    :return: enc_sentence: encoded tokens of the sentence\n",
    "                gold_path: gold path of the sentence\n",
    "               gold_moves: gold moves of the sentence\n",
    "                     gold: gold heads of the sentence\n",
    "    \"\"\"\n",
    "    sentence = [\"<ROOT>\"] + sample[\"tokens\"]\n",
    "    head = [(-1)] + list(map(int, sample[\"head\"]))  # [int(i) for i in tokens[\"head\"]]\n",
    "\n",
    "    # embedding ids of sentence words\n",
    "    enc_sentence = [\n",
    "        emb_dictionary[word] if word in emb_dictionary else emb_dictionary[\"<unk>\"]\n",
    "        for word in sentence\n",
    "    ]\n",
    "\n",
    "    if get_gold_path:\n",
    "        gold_moves, gold_path, _ = generate_gold(\n",
    "            sentence, head\n",
    "        )  # transform matrix from nx3 to 3xn\n",
    "    else:\n",
    "        gold_path, gold_moves = [], []\n",
    "\n",
    "    return enc_sentence, gold_path, gold_moves, head\n",
    "\n",
    "\n",
    "def process_batch(\n",
    "    batch: List[List], emb_dictionary: dict[str, int], get_gold_path: bool = False\n",
    ") -> List[NNData]:\n",
    "    pack: List[NNData] = []\n",
    "\n",
    "    for sample in batch:\n",
    "        s, c, m, h = process_sample(sample, emb_dictionary, get_gold_path=get_gold_path)\n",
    "        pack.append(NNData(s, c, m, h))\n",
    "\n",
    "    return pack\n",
    "\n",
    "\n",
    "def train(model: nn.Module, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    count = 1\n",
    "    for batch in dataloader:\n",
    "        print(f\"TRAIN: batch {count}/{len(dataloader):.0f}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(batch)\n",
    "        if isinstance(batch[0], NNData):\n",
    "            moves = extract_att(batch, \"moves\")\n",
    "        else:\n",
    "            moves = extract_att(batch[1], \"moves\")\n",
    "\n",
    "        labels = torch.tensor(sum(moves, [])).to(\n",
    "            device\n",
    "        )  # sum(moves, []) flatten the array\n",
    "\n",
    "        loss = criterion(out, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "\n",
    "    return total_loss / count\n",
    "\n",
    "\n",
    "def evaluate(gold: List[List[int]], preds: List[List[int]]):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for g, p in zip(gold, preds):\n",
    "        for i in range(1, len(g)):\n",
    "            total += 1\n",
    "            if g[i] == p[i]:\n",
    "                correct += 1\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def test(model, dataloader: torch.utils.data.dataloader):  # type:ignore\n",
    "    model.eval()\n",
    "\n",
    "    gold = []\n",
    "    preds = []\n",
    "    count = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        count += 1\n",
    "        print(f\"test: batch {count}/{len(dataloader):.0f}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model.infere(batch)\n",
    "            if isinstance(batch[0], NNData):\n",
    "                gold += extract_att(batch, \"heads\")\n",
    "            else:\n",
    "                gold += extract_att(batch[1], \"heads\")\n",
    "            preds += pred\n",
    "\n",
    "    return evaluate(gold, preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNParameters:\n",
    "    def __init__(self) -> None:\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.EMBEDDING_SIZE = 200\n",
    "        self.FREEZE = True\n",
    "        self.LSTM_SIZE = 200\n",
    "        self.LSTM_LAYERS = 2\n",
    "\n",
    "        self.MLP_OUT_SIZE = self.LSTM_LAYERS * self.LSTM_SIZE\n",
    "        self.OUT_CLASSES = 4\n",
    "\n",
    "        self.DROP_OUT = 0.2\n",
    "        self.LR = 0.001\n",
    "        self.EPOCHS = 50\n",
    "\n",
    "\n",
    "nnp = NNParameters()\n",
    "\n",
    "\n",
    "class BiLSTMNet(nn.Module):\n",
    "    def __init__(self, device, dictionary, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.device = device\n",
    "        self.embeddings = nn.Embedding(\n",
    "            len(dictionary), nnp.EMBEDDING_SIZE, padding_idx=dictionary[\"<pad>\"]\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            nnp.EMBEDDING_SIZE,\n",
    "            nnp.LSTM_SIZE,\n",
    "            num_layers=nnp.LSTM_LAYERS,\n",
    "            bidirectional=True,\n",
    "            dropout=nnp.DROP_OUT,\n",
    "        )\n",
    "\n",
    "        self.w1 = nn.Linear(\n",
    "            2 * nnp.LSTM_LAYERS * nnp.LSTM_SIZE, nnp.MLP_OUT_SIZE, bias=True\n",
    "        )\n",
    "        # self.w1 = nn.Linear(2 * nnp.LSTM_LAYERS * nnp.LSTM_SIZE, 100, bias=True)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.w2 = nn.Linear(nnp.MLP_OUT_SIZE, nnp.OUT_CLASSES, bias=True)\n",
    "        # self.w2 = nn.Linear(100, nnp.OUT_CLASSES, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(nnp.DROP_OUT)\n",
    "\n",
    "    def get_mlp_input(self, configurations, h):\n",
    "        mlp_input = []\n",
    "        zero_tensor = torch.zeros(\n",
    "            2 * nnp.LSTM_SIZE, requires_grad=False, device=self.device\n",
    "        )\n",
    "        for i in range(len(configurations)):\n",
    "            for j in configurations[i]:  # for each configuration of a sentence\n",
    "                mlp_input.append(\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            zero_tensor if j[0] == -1 else h[j[0]][i],\n",
    "                            zero_tensor if j[1] == -1 else h[j[1]][i],\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "        mlp_input = torch.stack(mlp_input).to(self.device)\n",
    "        return mlp_input\n",
    "\n",
    "    def mlp_pass(self, x):\n",
    "        return self.softmax(\n",
    "            self.w2(self.dropout(self.activation(self.w1(self.dropout(x)))))\n",
    "        )\n",
    "\n",
    "    def lstm_pass(self, x):\n",
    "        x = torch.nn.utils.rnn.pack_sequence(x, enforce_sorted=False)\n",
    "        h, _ = self.lstm(x)\n",
    "        h, _ = torch.nn.utils.rnn.pad_packed_sequence(h)\n",
    "        return h\n",
    "\n",
    "    def forward(self, batch: List[NNData]):\n",
    "        tokens = extract_att(batch, \"enc_tokens\")\n",
    "        x = [\n",
    "            self.dropout(self.embeddings(torch.tensor(t).to(self.device)))\n",
    "            for t in tokens\n",
    "        ]\n",
    "\n",
    "        h = self.lstm_pass(x)\n",
    "\n",
    "        configurations: List[List[Tuple[int, int]]] = extract_att(batch, \"confs\")\n",
    "        mlp_input = self.get_mlp_input(configurations, h)\n",
    "        out = self.mlp_pass(mlp_input)\n",
    "        return out\n",
    "\n",
    "    def infere(self, batch):\n",
    "        tokens = extract_att(batch, \"enc_tokens\")\n",
    "        parsers: List[ArcEager] = [ArcEager(t) for t in tokens]\n",
    "\n",
    "        x = [self.embeddings(torch.tensor(t).to(self.device)) for t in tokens]\n",
    "        h = self.lstm_pass(x)\n",
    "\n",
    "        is_final = [False]\n",
    "        while not all(is_final):\n",
    "            # get the current configuration and score next moves\n",
    "            configurations = [[p.get_configuration_now()] for p in parsers]\n",
    "            mlp_input = self.get_mlp_input(configurations, h)\n",
    "            mlp_out = self.mlp_pass(mlp_input)\n",
    "            # take the next parsing step\n",
    "            list_moves = parse_moves(parsers, mlp_out)\n",
    "            for i, m in enumerate(list_moves):\n",
    "                parsers[i].do_move(m)\n",
    "            is_final = [t.is_tree_final() for t in parsers]\n",
    "\n",
    "        # return the predicted dependency tree\n",
    "        return [parser.list_arcs for parser in parsers]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = create_dictionary(train_dataset)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=nnp.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: process_batch(x, dictionary, get_gold_path=True),\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=nnp.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: process_batch(x, dictionary, get_gold_path=True),\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=nnp.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: process_batch(x, dictionary, get_gold_path=False),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO SOMETHING !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/50\n",
      "TRAIN: batch 1/12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnnp\u001b[39m.\u001b[39mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# torch.load(f\"bilstm_e{epoch+1}.pt\")\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m avg_train_loss \u001b[39m=\u001b[39m train(model, train_dataloader, criterion, optimizer)\n\u001b[0;32m      9\u001b[0m val_uas \u001b[39m=\u001b[39m test(model, validation_dataloader)\n\u001b[0;32m     11\u001b[0m log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m3d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | avg_train_loss: \u001b[39m\u001b[39m{\u001b[39;00mavg_train_loss\u001b[39m:\u001b[39;00m\u001b[39m5.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | dev_uas: \u001b[39m\u001b[39m{\u001b[39;00mval_uas\u001b[39m:\u001b[39;00m\u001b[39m5.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m |\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[9], line 100\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTRAIN: batch \u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(dataloader)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 100\u001b[0m out \u001b[39m=\u001b[39m model(batch)\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(batch[\u001b[39m0\u001b[39m], NNData):\n\u001b[0;32m    102\u001b[0m     moves \u001b[39m=\u001b[39m extract_att(batch, \u001b[39m\"\u001b[39m\u001b[39mmoves\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\andri\\miniconda3\\envs\\nlp_cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Users\\andri\\miniconda3\\envs\\nlp_cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[10], line 85\u001b[0m, in \u001b[0;36mBiLSTMNet.forward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     82\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm_pass(x)\n\u001b[0;32m     84\u001b[0m configurations: List[List[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]]] \u001b[39m=\u001b[39m extract_att(batch, \u001b[39m\"\u001b[39m\u001b[39mconfs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m mlp_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_mlp_input(configurations, h)\n\u001b[0;32m     86\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_pass(mlp_input)\n\u001b[0;32m     87\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "Cell \u001b[1;32mIn[10], line 54\u001b[0m, in \u001b[0;36mBiLSTMNet.get_mlp_input\u001b[1;34m(self, configurations, h)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(configurations)):\n\u001b[0;32m     52\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m configurations[i]:  \u001b[39m# for each configuration of a sentence\u001b[39;00m\n\u001b[0;32m     53\u001b[0m         mlp_input\u001b[39m.\u001b[39mappend(\n\u001b[1;32m---> 54\u001b[0m             torch\u001b[39m.\u001b[39;49mcat(\n\u001b[0;32m     55\u001b[0m                 [\n\u001b[0;32m     56\u001b[0m                     zero_tensor \u001b[39mif\u001b[39;49;00m j[\u001b[39m0\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39melse\u001b[39;49;00m h[j[\u001b[39m0\u001b[39;49m]][i],\n\u001b[0;32m     57\u001b[0m                     zero_tensor \u001b[39mif\u001b[39;49;00m j[\u001b[39m1\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39melse\u001b[39;49;00m h[j[\u001b[39m1\u001b[39;49m]][i],\n\u001b[0;32m     58\u001b[0m                 ]\n\u001b[0;32m     59\u001b[0m             )\n\u001b[0;32m     60\u001b[0m         )\n\u001b[0;32m     61\u001b[0m mlp_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(mlp_input)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m mlp_input\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BiLSTMNet(device, dictionary).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=nnp.LR)\n",
    "\n",
    "for epoch in range(nnp.EPOCHS):\n",
    "    print(f\"Starting Epoch {epoch+1}/{nnp.EPOCHS}\")\n",
    "    # torch.load(f\"bilstm_e{epoch+1}.pt\")\n",
    "    avg_train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    val_uas = test(model, validation_dataloader)\n",
    "\n",
    "    log = f\"Epoch: {epoch:3d} | avg_train_loss: {avg_train_loss:5.3f} | dev_uas: {val_uas:5.3f} |\"\n",
    "    print(log)\n",
    "\n",
    "    # save the model on pytorch format\n",
    "    torch.save(model.state_dict(), f\"bilstm_e{epoch+1}.pt\")\n",
    "\n",
    "test_uas = test(model, test_dataloader)\n",
    "log = \"test_uas: {:5.3f}\".format(test_uas)\n",
    "print(log)\n",
    "train(model, train_dataloader, criterion, optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNParameters:\n",
    "    def __init__(self) -> None:\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.BERT_SIZE = 768\n",
    "        self.EMBEDDING_SIZE = self.BERT_SIZE\n",
    "        self.DIM_CONFIG = 2\n",
    "        self.MLP1_IN_SIZE = self.DIM_CONFIG * self.EMBEDDING_SIZE\n",
    "        self.MLP2_IN_SIZE = 300\n",
    "        self.OUT_CLASSES = 4\n",
    "        self.FREEZE = True\n",
    "        self.DROP_OUT = 0.2\n",
    "        self.LR = 0.01\n",
    "        self.EPOCHS = 50\n",
    "\n",
    "\n",
    "nnp = NNParameters()\n",
    "\n",
    "\n",
    "class NNData:\n",
    "    def __init__(self, sentence, confs, moves, heads, subw2word_idx) -> None:\n",
    "        self.sentence = sentence\n",
    "        self.confs = confs\n",
    "        self.moves = moves\n",
    "        self.heads = heads\n",
    "        self.subw2word_idx = subw2word_idx\n",
    "\n",
    "\n",
    "def extract_att(data: List[NNData], attribute: str):\n",
    "    return [getattr(d, attribute) for d in data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.add_tokens([\"<ROOT>\", \"<EMPTY>\"], special_tokens=True)\n",
    "\n",
    "\n",
    "def calcualate_subw2word_idx(subw_idx):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(subw_idx)\n",
    "    i = 0\n",
    "    o = []\n",
    "    while i < len(tokens):\n",
    "        t = []\n",
    "        t.append(i)\n",
    "        i += 1\n",
    "        while i < len(tokens) and tokens[i].startswith(\"##\"):\n",
    "            t.append(i)\n",
    "            i += 1\n",
    "        o.append(t)\n",
    "    return o\n",
    "\n",
    "\n",
    "def process_sample(sample, sentence, iid, get_gold_path=False):\n",
    "    \"\"\"\n",
    "    Process a sample from the dataset\n",
    "    1. Add [\"<ROOT>\"] to the beginning of the sentence and [-1] to the beginning of the head\n",
    "    2. Encode the sentence and the gold path\n",
    "\n",
    "\n",
    "    :param         tokens: tokens of a sentence\n",
    "    :param emb_dictionary: dictionary of word/index pairs\n",
    "    :param  get_gold_path: if True, we also return the gold path and gold moves\n",
    "    :return: enc_sentence: encoded tokens of the sentence\n",
    "                gold_path: gold path of the sentence\n",
    "               gold_moves: gold moves of the sentence\n",
    "                     gold: gold heads of the sentence\n",
    "    \"\"\"\n",
    "\n",
    "    head = [(-1)] + list(map(int, sample[\"head\"]))  # [int(i) for i in tokens[\"head\"]]\n",
    "\n",
    "    # embedding ids of sentence words\n",
    "    subw2word_idx = calcualate_subw2word_idx(iid)\n",
    "\n",
    "    if get_gold_path:\n",
    "        gold_moves, gold_path, _ = generate_gold(\n",
    "            sentence, head\n",
    "        )  # transform matrix from nx3 to 3xn\n",
    "    else:\n",
    "        gold_path, gold_moves = [], []\n",
    "\n",
    "    return head, gold_path, gold_moves, subw2word_idx\n",
    "\n",
    "\n",
    "def process_batch(batch: List[List], tokenizer, get_gold_path: bool = False):\n",
    "    pack: List[NNData] = []\n",
    "    sentences = [[\"<ROOT>\"] + bd[\"tokens\"] for bd in batch]\n",
    "\n",
    "    ## Tokenizer -> get token_ids, attention_mask and token_type_ids\n",
    "    output_tokenizer = tokenizer(\n",
    "        [\"<ROOT> \" + bd[\"text\"] for bd in batch],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "    token_ids: List[List[int]] = output_tokenizer[\"input_ids\"]\n",
    "    attention_mask = output_tokenizer[\"attention_mask\"]\n",
    "    token_types_ids = output_tokenizer[\"token_type_ids\"]\n",
    "    ###########\n",
    "    ## What is left? heads, gold_path, gold_moves, subw2word_idx\n",
    "    ## What i need? sample -> heads, original sentence -> golds, input_ids -> subw2word_idx\n",
    "    for sample, sentence, iid in zip(batch, sentences, token_ids):\n",
    "        head, configuration, moves, s2w = process_sample(\n",
    "            sample, sentence, iid, get_gold_path=get_gold_path\n",
    "        )\n",
    "        pack.append(NNData(sentence, configuration, moves, head, s2w))\n",
    "\n",
    "    return output_tokenizer, pack"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTNet(nn.Module):\n",
    "    def __init__(self, device, tokenizer, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.device = device\n",
    "        self.embeddings = nn.Embedding(\n",
    "            len(tokenizer), nnp.EMBEDDING_SIZE, padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.bert.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        # Freeze bert layers\n",
    "        if nnp.FREEZE:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.w1 = nn.Linear(1536, 300, bias=True)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.w2 = nn.Linear(300, 4, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(nnp.DROP_OUT)\n",
    "\n",
    "    def get_embedding(self, h, idx):\n",
    "        return torch.mean(h[idx], dim=0)\n",
    "\n",
    "    def get_mlp_input(self, configurations, subw2idx, h):\n",
    "        mlp_input = []\n",
    "        zero_tensor = torch.zeros(\n",
    "            nnp.BERT_SIZE, requires_grad=False, device=self.device\n",
    "        )\n",
    "        for i in range(len(configurations)):\n",
    "            for j in configurations[i]:  # for each configuration of a sentence\n",
    "                mlp_input.append(\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            zero_tensor\n",
    "                            if j[0] == -1\n",
    "                            else self.get_embedding(h[i], subw2idx[i][j[0]]),\n",
    "                            zero_tensor\n",
    "                            if j[1] == -1\n",
    "                            else self.get_embedding(h[i], subw2idx[i][j[1]]),\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "        mlp_input = torch.stack(mlp_input).to(self.device)\n",
    "        return mlp_input\n",
    "\n",
    "    def mlp_pass(self, x):\n",
    "        return self.softmax(\n",
    "            self.w2(self.dropout(self.activation(self.w1(self.dropout(x)))))\n",
    "        )\n",
    "\n",
    "    def forward(self, batch: Tuple[BatchEncoding, List[NNData]]):\n",
    "        output_tokenizer = batch[0].to(self.device)\n",
    "        input_ids = output_tokenizer[\"input_ids\"]\n",
    "        attention_mask = output_tokenizer[\"attention_mask\"]\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        attention_mask = attention_mask.to(self.device)\n",
    "\n",
    "        h = self.bert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).last_hidden_state.to(self.device)\n",
    "\n",
    "        nndata = batch[1]\n",
    "        configurations = extract_att(nndata, \"confs\")\n",
    "        subw2idx = extract_att(nndata, \"subw2word_idx\")\n",
    "        mlp_input = self.get_mlp_input(configurations, subw2idx, h)\n",
    "\n",
    "        out = self.mlp_pass(mlp_input)\n",
    "        return out\n",
    "\n",
    "    def infere(self, batch):\n",
    "        output_tokenizer, nndata = batch\n",
    "        output_tokenizer = output_tokenizer.to(self.device)\n",
    "        input_ids = output_tokenizer[\"input_ids\"]\n",
    "        attention_mask = output_tokenizer[\"attention_mask\"]\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        attention_mask = attention_mask.to(self.device)\n",
    "\n",
    "        h = self.bert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).last_hidden_state.to(self.device)\n",
    "\n",
    "        tokens = extract_att(nndata, \"sentence\")\n",
    "        parsers: List[ArcEager] = [ArcEager(t) for t in tokens]\n",
    "\n",
    "        subw2idx = extract_att(nndata, \"subw2word_idx\")\n",
    "        is_final = [False]\n",
    "        while not all(is_final):\n",
    "            # get the current configuration and score next moves\n",
    "            configurations = [[p.get_configuration_now()] for p in parsers]\n",
    "            mlp_input = self.get_mlp_input(configurations, subw2idx, h)\n",
    "            mlp_out = self.mlp_pass(mlp_input)\n",
    "            # take the next parsing step\n",
    "            list_moves = parse_moves(parsers, mlp_out)\n",
    "            for i, m in enumerate(list_moves):\n",
    "                parsers[i].do_move(m)\n",
    "            is_final = [t.is_tree_final() for t in parsers]\n",
    "\n",
    "        # return the predicted dependency tree\n",
    "        return [parser.list_arcs for parser in parsers]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=nnp.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: process_batch(x, tokenizer, get_gold_path=True),\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=nnp.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: process_batch(x, tokenizer, get_gold_path=True),\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=nnp.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: process_batch(x, tokenizer, get_gold_path=False),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO SOMETHING !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n",
      "TRAIN: batch 10/12\n",
      "TRAIN: batch 11/12\n",
      "TRAIN: batch 12/12\n",
      "test: batch 1/4\n",
      "test: batch 2/4\n",
      "test: batch 3/4\n",
      "test: batch 4/4\n",
      "Epoch:   0 | avg_train_loss: 1.171 | dev_uas: 0.338 |\n",
      "Starting Epoch 1\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n",
      "TRAIN: batch 10/12\n",
      "TRAIN: batch 11/12\n",
      "TRAIN: batch 12/12\n",
      "Epoch:   1 | avg_train_loss: 1.043 | dev_uas: -1.000 |\n",
      "Starting Epoch 2\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n",
      "TRAIN: batch 10/12\n",
      "TRAIN: batch 11/12\n",
      "TRAIN: batch 12/12\n",
      "Epoch:   2 | avg_train_loss: 1.004 | dev_uas: -1.000 |\n",
      "Starting Epoch 3\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n",
      "TRAIN: batch 10/12\n",
      "TRAIN: batch 11/12\n",
      "TRAIN: batch 12/12\n",
      "Epoch:   3 | avg_train_loss: 0.986 | dev_uas: -1.000 |\n",
      "Starting Epoch 4\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n",
      "TRAIN: batch 10/12\n",
      "TRAIN: batch 11/12\n",
      "TRAIN: batch 12/12\n",
      "Epoch:   4 | avg_train_loss: 0.975 | dev_uas: -1.000 |\n",
      "Starting Epoch 5\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n",
      "TRAIN: batch 10/12\n",
      "TRAIN: batch 11/12\n",
      "TRAIN: batch 12/12\n",
      "test: batch 1/4\n",
      "test: batch 2/4\n",
      "test: batch 3/4\n",
      "test: batch 4/4\n",
      "Epoch:   5 | avg_train_loss: 0.968 | dev_uas: 0.566 |\n",
      "Starting Epoch 6\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n",
      "TRAIN: batch 10/12\n",
      "TRAIN: batch 11/12\n",
      "TRAIN: batch 12/12\n",
      "Epoch:   6 | avg_train_loss: 0.963 | dev_uas: -1.000 |\n",
      "Starting Epoch 7\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n",
      "TRAIN: batch 10/12\n",
      "TRAIN: batch 11/12\n",
      "TRAIN: batch 12/12\n",
      "Epoch:   7 | avg_train_loss: 0.958 | dev_uas: -1.000 |\n",
      "Starting Epoch 8\n",
      "TRAIN: batch 1/12\n",
      "TRAIN: batch 2/12\n",
      "TRAIN: batch 3/12\n",
      "TRAIN: batch 4/12\n",
      "TRAIN: batch 5/12\n",
      "TRAIN: batch 6/12\n",
      "TRAIN: batch 7/12\n",
      "TRAIN: batch 8/12\n",
      "TRAIN: batch 9/12\n"
     ]
    }
   ],
   "source": [
    "model = BERTNet(device, tokenizer).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=nnp.LR)\n",
    "\n",
    "for epoch in range(nnp.EPOCHS):\n",
    "    print(\"Starting Epoch\", epoch)\n",
    "    # torch.load(f\"bilstm_e{epoch+1}.pt\")\n",
    "    avg_train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    val_uas = test(model, validation_dataloader)\n",
    "\n",
    "    log = f\"Epoch: {epoch:3d} | avg_train_loss: {avg_train_loss:5.3f} | dev_uas: {val_uas:5.3f} |\"\n",
    "    print(log)\n",
    "\n",
    "    # save the model on pytorch format\n",
    "    torch.save(model.state_dict(), f\"bilstm_e{epoch+1}.pt\")\n",
    "\n",
    "test_uas = test(model, test_dataloader)\n",
    "log = \"test_uas: {:5.3f}\".format(test_uas)\n",
    "print(log)\n",
    "train(model, train_dataloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
